#Event-Assisted RGB Fusion for Motion-Blur Robust Object Detection

This project demonstrates a lightweight RGBâ€“Event fusion pipeline for improving object detection performance under motion blur. The system integrates event camera data with conventional RGB frames using a deterministic overlay-based fusion strategy, without modifying the detection network.

âš¡ Optimized for real-time deployment on AMD Xilinx Kria KV260 with Prophesee IMX636 Event Camera

#ğŸ“· Features

âœ… RGB + Event data fusion without model modification

âœ… Synthetic event generation using V2E

âœ… Polarity-based event overlay (ON/OFF events)

âœ… YOLOv8-compatible inference pipeline

âœ… Motion-blur robust object detection

âœ… Real-time event camera deployment on Kria KV260

âœ… PetaLinux BSP bring-up and media pipeline debugging

âœ… Embedded latency and system-level evaluation

#ğŸ§  Methodology

RGB videos are converted into synthetic event streams using V2E

Events are accumulated over short temporal windows to form 2D event frames

Event frames are temporally and spatially aligned with RGB images

Polarity-encoded events are overlaid onto RGB frames

Fused images are directly used for YOLOv8 training and inference

#ğŸ“Š Dataset

1,470 car images collected from public YouTube videos

Motion blur simulated using directional blur kernels

Synthetic event data generated using DAVIS-style sensor configuration

Dataset variants:

RGB-only (blurred)

Event-only

Fused RGBâ€“Event

#ğŸ–¥ï¸ Hardware Platform

Event Camera: Prophesee IMX636 (DVS)

Embedded Board: AMD Xilinx Kria KV260

OS: PetaLinux BSP

Bring-Up Highlights

Device tree configuration for event camera

media-ctl pipeline debugging

Kernel driver validation

Custom WIC image flashing

Stable real-time event data streaming

#ğŸ§ª Training & Inference

Model: YOLOv8-M

Image Size: 640 Ã— 640

Optimizer: AdamW (Cosine LR)

Epochs: 100

Batch Size: 8

Embedded inference includes RGB + Event fusion, YOLOv8 deployment, and latency evaluation on KV260.

#ğŸ“ˆ Results
